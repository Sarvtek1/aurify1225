name: Deploy Aurify SSR to Cloud Run (me-central1)

on:
  push:
    branches: [ master ]
    paths:
      - "aurify-web/**"
      - ".github/workflows/deploy-cloudrun.yml"

permissions:
  contents: read
  id-token: write

env:
  GCP_PROJECT_ID: aurify1225
  GCP_REGION: me-central1

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up gcloud (with BigQuery CLI)
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.GCP_PROJECT_ID }}
          install_components: bq

      - name: Verify gcloud context
        shell: bash
        run: |
          gcloud --version
          bq --version || true
          gcloud config list

      # PDPL guard - BigQuery dataset residency & retention (verbose + robust)
      - name: "PDPL guard - BigQuery residency & retention"
        shell: bash
        env:
          WRITER_SA: service-671472133551@gcp-sa-logging.iam.gserviceaccount.com
          DATASET_ID: aurify_logs
          BQ_LOCATION: ME-CENTRAL1
        run: |
          set -euo pipefail

          echo "Installing jq for structured JSON checks..."
          sudo apt-get update -y >/dev/null
          sudo apt-get install -y jq >/dev/null

          echo "Fetching dataset JSON..."
          DS_JSON="$(bq --location="${BQ_LOCATION}" --project_id="${GCP_PROJECT_ID}" show --format=json "${DATASET_ID}")" || {
            echo "ERROR: Dataset ${DATASET_ID} not found in project ${GCP_PROJECT_ID} (location ${BQ_LOCATION})"
            exit 1
          }

          echo "Dataset JSON:"
          echo "${DS_JSON}" | jq .

          # 1) Check region = ME-CENTRAL1 (case-insensitive)
          LOCATION_LOWER="$(echo "${DS_JSON}" | jq -r '.location' | tr '[:upper:]' '[:lower:]')"
          if [[ "${LOCATION_LOWER}" != "me-central1" ]]; then
            echo "ERROR: Dataset ${DATASET_ID} in wrong location: '${LOCATION_LOWER}' (expected 'me-central1')"
            exit 1
          else
            echo "OK: Location ${LOCATION_LOWER}"
          fi

          # 2) Check default table expiration = 12 months
          EXP_MS="$(echo "${DS_JSON}" | jq -r '.defaultTableExpirationMs // empty')"
          if [[ -z "${EXP_MS}" ]]; then
            echo "ERROR: defaultTableExpirationMs is not set (expected 31536000000 ms = 12 months)"
            exit 1
          elif [[ "${EXP_MS}" != "31536000000" ]]; then
            echo "ERROR: defaultTableExpirationMs is ${EXP_MS} (expected 31536000000 ms = 12 months)"
            exit 1
          else
            echo "OK: Default table expiration ${EXP_MS} ms"
          fi

          # 3) Sink exists
          if ! gcloud logging sinks describe bq_aurify_logs >/dev/null 2>&1; then
            echo "ERROR: Logging sink 'bq_aurify_logs' not found"
            exit 1
          else
            echo "OK: Sink exists bq_aurify_logs"
          fi

          # 4) Sink writer has dataset IAM
          ACCESS_JSON="$(bq --location="${BQ_LOCATION}" --project_id="${GCP_PROJECT_ID}" show --format=prettyjson "${DATASET_ID}")"
          if echo "${ACCESS_JSON}" | jq -e --arg sa "${WRITER_SA}" '.access[]?|select(.userByEmail==$sa)' >/dev/null; then
            echo "OK: Sink writer IAM ${WRITER_SA}"
          else
            echo "ERROR: Sink writer ${WRITER_SA} missing on dataset IAM (add BigQuery Data Editor on ${DATASET_ID})"
            exit 1
          fi

          echo "SUCCESS: PDPL BigQuery checks passed (ME-CENTRAL1 + 12-month default + sink IAM)"

      # Non-failing pre-check: ok if service doesn't exist yet
      - name: Check Cloud Run service (allow not-found)
        shell: bash
        run: |
          if gcloud run services describe aurify-ssr \
               --region="${GCP_REGION}" \
               --project="${GCP_PROJECT_ID}" >/dev/null 2>&1; then
            echo "Service exists"
          else
            echo "Service not found yet (ok before first deploy)"
          fi

      - name: Ensure Artifact Registry exists (idempotent)
        shell: bash
        run: |
          gcloud artifacts repositories describe cloud-run-source-deploy \
            --location="${GCP_REGION}" \
            --project="${GCP_PROJECT_ID}" \
          || gcloud artifacts repositories create cloud-run-source-deploy \
               --location="${GCP_REGION}" \
               --repository-format=docker \
               --description="Cloud Run source builds for Aurify1225" \
               --project="${GCP_PROJECT_ID}"

      - name: Deploy to Cloud Run (me-central1)
        working-directory: ./aurify-web
        shell: bash
        run: |
          gcloud run deploy aurify-ssr \
            --region="${GCP_REGION}" \
            --allow-unauthenticated \
            --project="${GCP_PROJECT_ID}" \
            --source . \
            --set-env-vars=GCP_REGION="${GCP_REGION}" \
            --set-env-vars=BQ_LOCATION=ME-CENTRAL1 \
            --set-secrets=API_KEY=MY_API_KEY:latest

      - name: Verify deploy
        shell: bash
        run: |
          gcloud run services describe aurify-ssr \
            --region="${GCP_REGION}" \
            --project="${GCP_PROJECT_ID}" \
            --format="value(status.url)"
